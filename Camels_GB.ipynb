{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939c210d-98bb-40f7-a292-f033c7d54734",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import gumbel_r\n",
    "from matplotlib.pyplot import cm\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "import sympy\n",
    "from sympy import *\n",
    "from sympy import symbols, Eq, solve\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "\n",
    "output = 'Output58'\n",
    "Input = 'Input21'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1dc67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Catchment descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for the Seasonality Index\n",
    "def Seasonality_index(Annual_mean, Monthly_mean):\n",
    "    SI = (1/Annual_mean) * np.sum(np.abs(Monthly_mean - (Annual_mean/12)))\n",
    "    return SI\n",
    "\n",
    "#Function for Seasonality Timing Index\n",
    "def ST_calc(dP,dT):\n",
    "    days = 366\n",
    "    ST = dP[0] * np.sign(dT[0]) * np.cos((np.pi * (dP[1] - dT[1]))/days)\n",
    "    return ST\n",
    "\n",
    "#Functions to compute Seasonal variability indexes\n",
    "def T_daily(dT):\n",
    "    t = np.linspace(1,366,366)\n",
    "    days = 366\n",
    "    T = T_mean + dT[0] * np.sin((2*np.pi * (t-dT[1]))/days)\n",
    "    return T\n",
    "\n",
    "def Cal_T_daily(dT):\n",
    "    days = 366\n",
    "    T_calc = T_daily(dT)\n",
    "    \n",
    "    return (np.sum(np.abs(T_calc - T_obs)))/days\n",
    "\n",
    "def P_daily(dP):\n",
    "    t = np.linspace(1,366,366)\n",
    "    days = 366\n",
    "    P = P_mean * (1 + dP[0] * np.sin((2*np.pi * (t-dP[1]))/days))\n",
    "    return P\n",
    "\n",
    "def Cal_P_daily(dP):\n",
    "    days = 366\n",
    "    P_calc = P_daily(dP)\n",
    "    \n",
    "    return (np.sum(np.abs(P_calc - P_obs)))/days\n",
    "\n",
    "def E_daily(dE):\n",
    "#    t = np.linspace(1,366,366)\n",
    "    t = np.linspace(1,366,366)\n",
    "\n",
    "    days = 366\n",
    "    E = E_mean * (1 + dE[0] * np.sin((2*np.pi * (t-dE[1]))/days))\n",
    "    return E\n",
    "\n",
    "def Cal_E_daily(dE):\n",
    "    days = 366\n",
    "    E_calc = E_daily(dE)\n",
    "    \n",
    "    return (np.sum(np.abs(E_calc - E_obs)))/days\n",
    "\n",
    "#Function for the interstorm duration or low_prec_freq\n",
    "def Interstorm_duration(P):\n",
    "    interstorm = []\n",
    "    count = 0\n",
    "\n",
    "    for j in range(len(P)):\n",
    "        if P[j] < 1:\n",
    "            count += 1\n",
    "        elif P[j] >= 1 and count > 0:\n",
    "            interstorm.append(count)\n",
    "            count = 0 \n",
    "    interstorm_duration = np.mean(interstorm)\n",
    "    return interstorm_duration\n",
    "\n",
    "\n",
    "\n",
    "#Function to compute the root-zone storage capacity over total time period\n",
    "def rootzone(df_out, RP):\n",
    "    SD = years['SD_sum'].max() - years['SD_sum'].min()\n",
    "    var = gumbel_r.fit(SD)\n",
    "    p = 1-1/RP\n",
    "    Sr = gumbel_r.ppf(p, var[0],var[1])\n",
    "    return(Sr, df_out)\n",
    "\n",
    "\n",
    "#Function to compute the potential evaporation for CAMELS-GB\n",
    "def calc_Makkink_GB(Temp, Rs, timestep = 86400):\n",
    "    \"\"\"\n",
    "    Rs is hier in W/m2\n",
    "    om van straling unit knmi (J/cm2) naar W/m2 ----> Rs_unit_knmi * 2.77777 \n",
    "\tdeze formule is van komt van: https://nl.wikipedia.org/wiki/Referentie-gewasverdamping \n",
    "    \"\"\"\n",
    "    a = 6.1078\n",
    "    b = 17.294\n",
    "    c = 237.73\n",
    "    Eref = np.zeros(len(Temp))\n",
    "    for i in range(len(Temp)):\n",
    "        gamma=0.646+0.0006*Temp[i] \t\t\t\t#psychrometer constante (hPa/C)\n",
    "        labda=1000*(2501-2.38*Temp[i])\t\t\t#verdampingswarmte water (J/kg)\n",
    "        Slope = (a*b*c) / (c+Temp[i])**2 * np.exp(b*Temp[i] / (c+Temp[i]))   # \n",
    "        Eref[i] = 0.65 * Slope / (Slope + gamma) * Rs[i] / labda * timestep     #ref verd in mm/h ! \n",
    "    return Eref\n",
    "\n",
    "\n",
    "def w_function(AI, w):\n",
    "    EI = 1 + AI - (1 + (AI**w))**(1/w)\n",
    "    return EI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595cec6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Catchment selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68285e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CAMELS-GB: Catchment selection\n",
    "Check for human influence, if 'Y' this indicates a lot of human influence\n",
    "Frac_snow < 0.1 means no insignificant snow impact\n",
    "Saves the catchments to a list\n",
    "\"\"\"\n",
    "\n",
    "human_influence = pd.read_csv('1_Data\\8344e4f3-d2ea-44f5-8afa-86d2987543a9\\data\\CAMELS_GB_humaninfluence_attributes.csv')\n",
    "catch_attr = pd.read_csv('1_Data\\8344e4f3-d2ea-44f5-8afa-86d2987543a9\\data\\CAMELS_GB_climatic_attributes.csv')\n",
    "\n",
    "catchment_list_GB = []\n",
    "for i in range(len(human_influence)):\n",
    "    if (human_influence['benchmark_catch'][i] == 'Y')and (catch_attr['frac_snow'][i]<0.1):\n",
    "        catchment_list_GB.append(human_influence['gauge_id'][i])\n",
    "        \n",
    "\n",
    "removing_GB = [42010, 74001, 42016, 65001, 27084, 39101, 44009, 81004, 2002, 66004, 60012, 83010, 90003, 96002, 16003, 18011, 21006, 3003, 27073, 39028, 39065, 42008, 44006, 81002, 85003, 4005, 72014, 83006, 84022, 95001, 73015, 102001, 11004, 13004, 15023, 15025] # the first were because of exceeding of energy limit, the last (6) because of nanvalues for discharge\n",
    "\n",
    "for i in range(len(removing_GB)):\n",
    "    catchment_list_GB.remove(removing_GB[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab721f8-db64-4111-9385-f855e548e0f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba842c-8253-4625-a124-db8060ee36f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Determine time slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fd85b-4346-44b9-8761-73323c47e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yrcut = [1970, 1980, 1990, 2000, 2010] # het laatste jaar zit er niet in\n",
    "yrsl = []\n",
    "for i in range(len(yrcut)-1):\n",
    "    sl = f'{yrcut[i]+1} - {yrcut[i+1]}'\n",
    "    yrsl.append(sl)\n",
    "    \n",
    "print(yrsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1468ae8-dcf8-40dc-bc51-030080a87eab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Loop through catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672b80c-d1e9-4fa8-8dd7-291d3885f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "catchment_list = catchment_list_GB\n",
    "df_output = pd.DataFrame(index=catchment_list)\n",
    "df_output2 = pd.DataFrame()\n",
    "\n",
    "for i in range(len(catchment_list)):  \n",
    "    # Import data and select right dates\n",
    "    data = pd.read_csv('1_Data/8344e4f3-d2ea-44f5-8afa-86d2987543a9/data/timeseries/CAMELS_GB_hydromet_timeseries_'+str(catchment_list[i])+str(\"_19701001-20150930.csv\"), delimiter=',', parse_dates=[0], skipinitialspace=True)\n",
    "    data.loc[:,'dt'] = pd.to_datetime(data['date'])\n",
    "    data.index = data['dt']\n",
    "    data = data.loc[\"1971-01-01\":\"2010-12-31\"]        \n",
    "        \n",
    "    # Compute the Makkink potential evaporation\n",
    "    Eref = calc_Makkink_GB(data['temperature'],data['shortwave_rad'])\n",
    "    data['Ep_MAK'] = Eref\n",
    "        \n",
    "    # Compute mean values    \n",
    "    Ep = data['Ep_MAK'].mean()    \n",
    "    T = data['temperature'].mean()\n",
    "    P  = data['precipitation'].mean()\n",
    "    Q  = data['discharge_spec'].mean()\n",
    "        \n",
    "    # Compute actual evaporation and Evaporative Index and Aridity index\n",
    "    Ea = P - Q  \n",
    "    AI = Ep / P   \n",
    "    EI = Ea / P \n",
    "    \n",
    "    if AI < EI:\n",
    "        print(f'Exclude catchment with ID (2) {catchment_list[i]}')\n",
    "    \n",
    "    # Calculate root zone storage deficits\n",
    "    RP    = 20 # Return-period of 20 years\n",
    "    P_ts  = data['precipitation']\n",
    "    EP_ts = data['Ep_MAK']\n",
    "\n",
    "    Et = np.zeros(len(P_ts))\n",
    "    SD = np.zeros(len(P_ts))\n",
    "\n",
    "    for z in range(len(P_ts)):\n",
    "        Et[z] = (EP_ts[z]/Ep) * Ea\n",
    "        if z == 0:\n",
    "            SD[z] = min(0, P_ts[z] - Et[z])\n",
    "        else:\n",
    "            SD[z] = min(0, SD[z-1] + P_ts[z] - Et[z])\n",
    "    data.loc[:,'SD'] = SD\n",
    "            \n",
    "    data['year'] = pd.DatetimeIndex(data['date']).year\n",
    "    df_out = pd.DataFrame(index = data.index)\n",
    "    df_out['hydroyear'] = data['year']\n",
    "    df_out['SD_sum'] = data['SD']\n",
    "    Sr = rootzone(df_out,RP)[0]   \n",
    "    \n",
    "    #Annual precipitation values\n",
    "    data_y = data.resample('A').sum()\n",
    "    Pa = data_y['precipitation'].mean()\n",
    "    Epa = data_y['Ep_MAK'].mean()\n",
    "       \n",
    "    #monthly_mean_values:\n",
    "    data_m_sum = data.resample('M').sum()\n",
    "    monthly_sliced_sum = data_m_sum.groupby(data_m_sum.index.month).mean()\n",
    "    P_m_sum = np.zeros(12)\n",
    "    P_m_sum = monthly_sliced_sum['precipitation']\n",
    "        \n",
    "    data_m_mean = data.resample('M').mean()\n",
    "    monthly_sliced_mean = data_m_mean.groupby(data_m_mean.index.month).mean()\n",
    "    T_m_mean = np.zeros(12)\n",
    "    T_m_mean = monthly_sliced_mean['temperature']\n",
    "    \n",
    "    #Compute the seasonality variability indexes\n",
    "    data_d = data.resample('d').mean().bfill()\n",
    "    daily_sliced_mean = data.groupby([data_d.index.month, data_d.index.day]).agg(np.mean)\n",
    "    \n",
    "    T1 = np.zeros((366))\n",
    "    P1 = np.zeros((366))\n",
    "    E1 = np.zeros((366))\n",
    "    count = 0\n",
    "\n",
    "    \n",
    "    for k in range(1,13):\n",
    "        for m in range(1,len(daily_sliced_mean['temperature'][k])+1):\n",
    "            T1[count] = daily_sliced_mean['temperature'][k,m]\n",
    "            P1[count] = daily_sliced_mean['precipitation'][k,m]\n",
    "            E1[count] = daily_sliced_mean['Ep_MAK'][k,m]\n",
    "            count += 1\n",
    "    t = np.linspace(1,366,366)\n",
    "    \n",
    "    T_obs = T1\n",
    "    P_obs = P1\n",
    "    E_obs = E1\n",
    "\n",
    "    T_mean = np.nanmean(T_obs)\n",
    "    P_mean = np.nanmean(P_obs)\n",
    "    E_mean = np.nanmean(E_obs)\n",
    "\n",
    "    x0_T = [5, 110]\n",
    "    x0_P = [0.3, 40]\n",
    "    x0_E = [0.4, 40]\n",
    "    lb = [0, np.inf]\n",
    "    ub = [0, 366]\n",
    "    \n",
    "    res_T = minimize(Cal_T_daily, x0_T,method='Powell', bounds=(lb,ub))\n",
    "    res_P = minimize(Cal_P_daily, x0_P, method='Powell', bounds=(lb,ub))\n",
    "    res_E = minimize(Cal_E_daily, x0_E, method='Powell', bounds=(lb,ub))\n",
    "\n",
    "    dp = res_P.x[0]\n",
    "    sp = res_P.x[1] / 366\n",
    "    dt = res_T.x[0]\n",
    "    st = res_T.x[1] / 366\n",
    "        \n",
    "    if abs(sp - st) <= 0.5:\n",
    "        sd = sp - st\n",
    "\n",
    "    elif (sp - st) > 0.5:\n",
    "        sd = -1 + (sp - st)\n",
    "\n",
    "    else:\n",
    "        sd = 1 + (sp - st)\n",
    "\n",
    "    de = res_E.x[0]\n",
    "    se = res_E.x[1] / 366\n",
    "    \n",
    "    \n",
    "\n",
    "    # Compute variables\n",
    "    ST = ST_calc(res_P.x,res_T.x)\n",
    "    SI = Seasonality_index(Pa, P_m_sum)\n",
    "    is_dur = Interstorm_duration(data['precipitation'])\n",
    "    \n",
    "    \n",
    "    if AI < EI or Ea < 0:\n",
    "        print(f'Exclude catchment with ID {catchment_list[i]}')\n",
    "        \n",
    "    budyko_curve_x = np.arange(1, 3, 0.05)\n",
    "    energy_limit_x = np.arange(0, 1.0001, 0.05)\n",
    "    x = np.arange(0, 1.0001, 0.05)\n",
    "    water_limit_y = 1 + budyko_curve_x*0\n",
    "    energy_limit_y = energy_limit_x\n",
    "    y = 1 + x*0\n",
    "        \n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(10)\n",
    "    plt.suptitle(f'catchment_with_ID{catchment_list[i]}')\n",
    "\n",
    "    axs[0].plot(energy_limit_x, energy_limit_y, c='k')\n",
    "    axs[0].plot(budyko_curve_x, water_limit_y,c='k')\n",
    "\n",
    "    axs[0].set_ylabel(\"Actual ET/P\")\n",
    "    axs[0].set_xlabel(\"Potential ET/P\")\n",
    "    axs[0].minorticks_on()\n",
    "        \n",
    "    # plot annual deficits\n",
    "    axs[1].set_ylabel(f'Root zone storage deficit [mm]')\n",
    "    \n",
    "    \n",
    "    df_output.loc[catchment_list[i],[f'AI']] = AI\n",
    "    df_output.loc[catchment_list[i],[f'EI']] = EI\n",
    "    df_output.loc[catchment_list[i],[f'Pa']] = Pa\n",
    "    df_output.loc[catchment_list[i],[f'Epa']] = Epa\n",
    "    df_output.loc[catchment_list[i],[f'T']] = T\n",
    "    df_output.loc[catchment_list[i],[f'is_dur']] = is_dur\n",
    "    df_output.loc[catchment_list[i],[f'SI']] = SI\n",
    "    df_output.loc[catchment_list[i],[f'ST']] = ST\n",
    "    df_output.loc[catchment_list[i],[f'Sr']] = Sr\n",
    "\n",
    "\n",
    "    \n",
    "    # Seperate data into slices\n",
    "    data['year'] = pd.DatetimeIndex(data['date']).year\n",
    "    for j in range(len(yrsl)):\n",
    "        datanew = data.loc[(yrcut[j] <= data['year']) & (data['year'] < yrcut[j+1])]\n",
    "        data_past_decades = data.loc[(yrcut[0] <= data['year']) & (data['year'] < yrcut[j+1])]\n",
    "        # display(data_past_decades)\n",
    "        c = colors[j]\n",
    "        yearslice = yrsl[j]\n",
    "        \n",
    "        # Compute the Makkink potential evaporation\n",
    "        Ep = datanew['Ep_MAK'].mean()    \n",
    "        T = datanew['temperature'].mean()\n",
    "        P  = datanew['precipitation'].mean()\n",
    "        Q  = datanew['discharge_spec'].mean()\n",
    "        \n",
    "\n",
    "        # Compute actual evaporation and Evaporative Index and Aridity index\n",
    "        Ea = P - Q  \n",
    "        AI = Ep / P   \n",
    "        EI = Ea / P \n",
    "            \n",
    "        if AI < EI:\n",
    "            print(f'Exclude catchment with ID (2) {catchment_list[i]}')\n",
    "                                \n",
    "        EI_line = np.linspace(EI, EI, 1000000)\n",
    "        w_array = np.linspace(0, 5000, 1000000)\n",
    "        Eq_tosolve = 1 + AI - (1 + (AI**w_array))**(1/w_array)\n",
    "\n",
    "        first_line = LineString(np.column_stack((w_array, EI_line)))\n",
    "        second_line = LineString(np.column_stack((w_array, Eq_tosolve)))\n",
    "        intersection = first_line.intersection(second_line)\n",
    "\n",
    "        w = intersection.x\n",
    "\n",
    "        # plot w function\n",
    "        AI_array = np.arange(0, 3, 0.05)\n",
    "        EI_out = w_function(AI_array, w)\n",
    "        axs[0].plot(AI_array, EI_out,color=c, linewidth = 0.5)\n",
    "        axs[0].plot(AI, EI, marker='o', color=c, label=f'omega = {w:.5f}',markersize=5)\n",
    "            \n",
    "        # Calculate root zone storage deficits\n",
    "        RP    = 20 # Return-period of 20 years\n",
    "        P_ts  = datanew['precipitation']\n",
    "        EP_ts = datanew['Ep_MAK']\n",
    "\n",
    "        Et = np.zeros(len(P_ts))\n",
    "        SD = np.zeros(len(P_ts))\n",
    "\n",
    "        for z in range(len(P_ts)):\n",
    "            Et[z] = (EP_ts[z]/Ep) * Ea\n",
    "            if z == 0:\n",
    "                SD[z] = min(0, P_ts[z] - Et[z])\n",
    "            else:\n",
    "                SD[z] = min(0, SD[z-1] + P_ts[z] - Et[z])\n",
    "        datanew.loc[:,'SD'] = SD\n",
    "\n",
    "        axs[1].plot(datanew['SD'], linewidth = 0.5, c=c)\n",
    "        \n",
    "            \n",
    "        datanew['year'] = pd.DatetimeIndex(datanew['date']).year\n",
    "        df_out = pd.DataFrame(index = datanew.index)\n",
    "        df_out['hydroyear'] = datanew['year']\n",
    "        df_out['SD_sum'] = datanew['SD']\n",
    "        Sr = rootzone(df_out,RP)[0]\n",
    "\n",
    "        #Annual precipitation values\n",
    "        data_y = datanew.resample('A').sum()\n",
    "        Pa = data_y['precipitation'].mean()\n",
    "        Epa = data_y['Ep_MAK'].mean()\n",
    "       \n",
    "        #monthly_mean_values:\n",
    "        data_m_sum = datanew.resample('M').sum()\n",
    "        monthly_sliced_sum = data_m_sum.groupby(data_m_sum.index.month).mean()\n",
    "        P_m_sum = np.zeros(12)\n",
    "        P_m_sum = monthly_sliced_sum['precipitation']\n",
    "        \n",
    "        data_m_mean = datanew.resample('M').mean()\n",
    "        monthly_sliced_mean = data_m_mean.groupby(data_m_mean.index.month).mean()\n",
    "        T_m_mean = np.zeros(12)\n",
    "        T_m_mean = monthly_sliced_mean['temperature']\n",
    "        \n",
    "        \n",
    "        #Compute the seasonality variability indexes\n",
    "        data_d = datanew.resample('d').mean().bfill()\n",
    "        daily_sliced_mean = datanew.groupby([data_d.index.month, data_d.index.day]).agg(np.mean)\n",
    "    \n",
    "        T1 = np.zeros((366))\n",
    "        P1 = np.zeros((366))\n",
    "        E1 = np.zeros((366))\n",
    "        count = 0\n",
    "\n",
    "    \n",
    "        for k in range(1,13):\n",
    "            for m in range(1,len(daily_sliced_mean['temperature'][k])+1):\n",
    "                T1[count] = daily_sliced_mean['temperature'][k,m]\n",
    "                P1[count] = daily_sliced_mean['precipitation'][k,m]\n",
    "                E1[count] = daily_sliced_mean['Ep_MAK'][k,m]\n",
    "                count += 1\n",
    "        t = np.linspace(1,366,366)\n",
    "    \n",
    "        T_obs = T1\n",
    "        P_obs = P1\n",
    "        E_obs = E1\n",
    "\n",
    "        T_mean = np.nanmean(T_obs)\n",
    "        P_mean = np.nanmean(P_obs)\n",
    "        E_mean = np.nanmean(E_obs)\n",
    "\n",
    "        x0_T = [5, 110]\n",
    "        x0_P = [0.3, 40]\n",
    "        x0_E = [0.4, 40]\n",
    "        lb = [0, np.inf]\n",
    "        ub = [0, 366]\n",
    "    \n",
    "        res_T = minimize(Cal_T_daily, x0_T,method='Powell', bounds=(lb,ub))\n",
    "        res_P = minimize(Cal_P_daily, x0_P, method='Powell', bounds=(lb,ub))\n",
    "        res_E = minimize(Cal_E_daily, x0_E, method='Powell', bounds=(lb,ub))\n",
    "\n",
    "        dp = res_P.x[0]\n",
    "        sp = res_P.x[1] / 366\n",
    "        dt = res_T.x[0]\n",
    "        st = res_T.x[1] / 366\n",
    "        \n",
    "        if abs(sp - st) <= 0.5:\n",
    "            sd = sp - st\n",
    "\n",
    "        elif (sp - st) > 0.5:\n",
    "            sd = -1 + (sp - st)\n",
    "\n",
    "        else:\n",
    "            sd = 1 + (sp - st)\n",
    "\n",
    "        de = res_E.x[0]\n",
    "        se = res_E.x[1] / 366\n",
    "\n",
    "        # Compute variables\n",
    "        ST = ST_calc(res_P.x,res_T.x)\n",
    "        HAI = HAI_calculate(T_m_mean, Pa)\n",
    "        SI = Seasonality_index(Pa, P_m_sum)\n",
    "        is_dur = Interstorm_duration(datanew['precipitation'])\n",
    "            \n",
    "        # Save to Output \n",
    "                \n",
    "        df_output.loc[catchment_list[i],[f'AI {yrsl[j]}']] = AI\n",
    "        df_output.loc[catchment_list[i],[f'EI {yrsl[j]}']] = EI\n",
    "        df_output.loc[catchment_list[i],[f'Pa {yrsl[j]}']] = Pa\n",
    "        df_output.loc[catchment_list[i],[f'Epa {yrsl[j]}']] = Epa\n",
    "        df_output.loc[catchment_list[i],[f'T {yrsl[j]}']] = T     \n",
    "        df_output.loc[catchment_list[i],[f'is_dur {yrsl[j]}']] = is_dur\n",
    "        df_output.loc[catchment_list[i],[f'SI {yrsl[j]}']] = SI\n",
    "        df_output.loc[catchment_list[i],[f'ST {yrsl[j]}']] = ST  \n",
    "        df_output.loc[catchment_list[i],[f'omega {yrsl[j]}']] = w\n",
    "        df_output.loc[catchment_list[i],[f'Sr actual {yrsl[j]}']] = Sr\n",
    "        \n",
    "        # w function past decades\n",
    "        \n",
    "        Ep = data_past_decades['Ep_MAK'].mean()    \n",
    "        T = data_past_decades['temperature'].mean()\n",
    "        P  = data_past_decades['precipitation'].mean()\n",
    "        Q  = data_past_decades['discharge_spec'].mean()\n",
    "        \n",
    "\n",
    "        # Compute actual evaporation and Evaporative Index and Aridity index\n",
    "        Ea = P - Q  \n",
    "        AI = Ep / P   \n",
    "        EI = Ea / P \n",
    "            \n",
    "        if AI < EI:\n",
    "            print(f'Exclude catchment with ID (3) {catchment_list[i]}')\n",
    "                                \n",
    "        EI_line = np.linspace(EI, EI, 1000000)\n",
    "        w_array = np.linspace(0, 5000, 1000000)\n",
    "        Eq_tosolve = 1 + AI - (1 + (AI**w_array))**(1/w_array)\n",
    "\n",
    "        first_line = LineString(np.column_stack((w_array, EI_line)))\n",
    "        second_line = LineString(np.column_stack((w_array, Eq_tosolve)))\n",
    "        intersection = first_line.intersection(second_line)\n",
    "\n",
    "        w = intersection.x\n",
    "        \n",
    "        df_output.loc[catchment_list[i],[f'omega past decades {yrsl[j]}']] = w\n",
    "\n",
    "            \n",
    "    axs[0].legend(loc='lower right')\n",
    "    plt.savefig(f'2_Output/{output}/Catchments/Budyko_and_deficits_nr_of_catchment_with_ID{catchment_list[i]}.png')   \n",
    "    plt.close(fig)\n",
    "    \n",
    "display(df_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c377e2-2d20-406b-88ad-93832e703340",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Calculate changes and output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eed96a-aac9-4d09-bcfd-3bdfca1997a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculate changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7b685-c984-4485-bbcc-8b0b044f4a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_names = ['Precipitation', 'Potential Evaporation', 'Temperature', 'Aridity Index', 'Seasonality Index', 'Interstorm duration', 'Seasonality Timing Index']\n",
    "descriptors = ['Pa', 'Epa', 'T', 'AI', 'SI', 'is_dur', 'ST']\n",
    "EI_dev_GB = []\n",
    "\n",
    "\n",
    "for i in range(len(catchment_list)):\n",
    "    for j in range(len(yrsl)-1):\n",
    "        AI = df_output.loc[catchment_list[i],[f'AI {yrsl[j+1]}']].item()\n",
    "        w = df_output.loc[catchment_list[i],[f'omega {yrsl[j]}']].item()\n",
    "        EI_exp = w_function(AI, w)\n",
    "        df_output.loc[[catchment_list[i]],[f'EI expected {yrsl[j+1]}']] = EI_exp\n",
    "\n",
    "for i in range(len(catchment_list)):\n",
    "    for j in range(len(yrsl)):\n",
    "        yr = yrsl[j]\n",
    "        if j > 0:\n",
    "            EI = df_output.loc[catchment_list[i],[f'EI {yrsl[j]}']].item()\n",
    "            EI_exp = df_output.loc[catchment_list[i],[f'EI expected {yrsl[j]}']].item()\n",
    "            EI_dev = EI - EI_exp\n",
    "            EI_dev_GB.append(EI_dev)\n",
    "            df_output.loc[[catchment_list[i]],[f'EI deviation {yrsl[j]}']] = EI_dev \n",
    "            \n",
    "            for k in range(len(descriptors)):\n",
    "                df_output.loc[[catchment_list[i]], [f'{descriptors[k]}_change {yr}']] = df_output.loc[catchment_list[i],[f'{descriptors[k]} {yrsl[j]}']].item() - df_output.loc[catchment_list[i],[f'{descriptors[k]} {yrsl[j-1]}']].item()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84080452-82df-4f3f-bbb0-36439f1ddcde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Make groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6d3d0-511f-4d08-a5c4-af5cb90887a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut1_Pa = 700\n",
    "cut2_Pa = 1400\n",
    "\n",
    "cut1_Epa = 500\n",
    "cut2_Epa = 750\n",
    "\n",
    "cut1_T = 10\n",
    "cut2_T = 15\n",
    "\n",
    "cut1_AI = 0.33\n",
    "cut2_AI = 0.66\n",
    "\n",
    "cut1_ST = 0\n",
    "cut2_ST = 0.10\n",
    "\n",
    "\n",
    "cut1_SI = 0.2\n",
    "cut2_SI = 0.4\n",
    "\n",
    "cut1_isdur = 4\n",
    "cut2_isdur = 6\n",
    "\n",
    "\n",
    "catchment_list_Pa1 = []\n",
    "catchment_list_Pa2 = []\n",
    "catchment_list_Pa3 = []\n",
    "\n",
    "catchment_list_Epa1 = []\n",
    "catchment_list_Epa2 = []\n",
    "catchment_list_Epa3 = []\n",
    "\n",
    "catchment_list_T1 = []\n",
    "catchment_list_T2 = []\n",
    "catchment_list_T3 = []\n",
    "\n",
    "catchment_list_AI1 = []\n",
    "catchment_list_AI2 = []\n",
    "catchment_list_AI3 = []\n",
    "\n",
    "catchment_list_ST1 = []\n",
    "catchment_list_ST2 = []\n",
    "catchment_list_ST3 = []\n",
    "\n",
    "catchment_list_SI1 = []\n",
    "catchment_list_SI2 = []\n",
    "catchment_list_SI3 = []\n",
    "\n",
    "catchment_list_isdur1 = []\n",
    "catchment_list_isdur2 = []\n",
    "catchment_list_isdur3 = []\n",
    "\n",
    "for i in range(len(catchment_list)):\n",
    "    if df_output.loc[catchment_list[i],'Pa'] < cut1_Pa:\n",
    "        catchment_list_Pa1.append(catchment_list[i])\n",
    "    elif cut1_Pa <= df_output.loc[catchment_list[i],'Pa'] < cut2_Pa:\n",
    "        catchment_list_Pa2.append(catchment_list[i])\n",
    "    elif cut2_Pa <= df_output.loc[catchment_list[i],'Pa']:\n",
    "        catchment_list_Pa3.append(catchment_list[i])\n",
    "        \n",
    "catchment_list_Pa = catchment_list_Pa1, catchment_list_Pa2, catchment_list_Pa3\n",
    "        \n",
    "        \n",
    "for i in range(len(catchment_list)):\n",
    "    if df_output.loc[catchment_list[i],'Epa'] < cut1_Epa:\n",
    "        catchment_list_Epa1.append(catchment_list[i])\n",
    "    elif cut1_Epa <= df_output.loc[catchment_list[i],'Epa'] < cut2_Epa:\n",
    "        catchment_list_Epa2.append(catchment_list[i])\n",
    "    elif cut2_Epa <= df_output.loc[catchment_list[i],'Epa']:\n",
    "        catchment_list_Epa3.append(catchment_list[i])\n",
    "        \n",
    "catchment_list_Epa = catchment_list_Epa1, catchment_list_Epa2, catchment_list_Epa3\n",
    "\n",
    "        \n",
    "for i in range(len(catchment_list)):\n",
    "    if df_output.loc[catchment_list[i],'T'] < cut1_T:\n",
    "        catchment_list_T1.append(catchment_list[i])\n",
    "    elif cut1_T <= df_output.loc[catchment_list[i],'T'] < cut2_T:\n",
    "        catchment_list_T2.append(catchment_list[i])\n",
    "    elif cut2_T <= df_output.loc[catchment_list[i],'T']:\n",
    "        catchment_list_T3.append(catchment_list[i])\n",
    "        \n",
    "catchment_list_T = catchment_list_T1, catchment_list_T2, catchment_list_T3\n",
    "\n",
    "for i in range(len(catchment_list)):\n",
    "    if df_output.loc[catchment_list[i],'AI'] < cut1_AI:\n",
    "        catchment_list_AI1.append(catchment_list[i])\n",
    "    elif cut1_AI <= df_output.loc[catchment_list[i],'AI'] < cut2_AI:\n",
    "        catchment_list_AI2.append(catchment_list[i])\n",
    "    elif cut2_AI <= df_output.loc[catchment_list[i],'AI']:\n",
    "        catchment_list_AI3.append(catchment_list[i])\n",
    "        \n",
    "catchment_list_AI = catchment_list_AI1, catchment_list_AI2, catchment_list_AI3\n",
    "\n",
    "for i in range(len(catchment_list)):\n",
    "    if df_output.loc[catchment_list[i],'ST'] < cut1_ST:\n",
    "        catchment_list_ST1.append(catchment_list[i])\n",
    "    elif cut1_ST <= df_output.loc[catchment_list[i],'ST'] < cut2_ST:\n",
    "        catchment_list_ST2.append(catchment_list[i])\n",
    "    elif cut2_ST <= df_output.loc[catchment_list[i],'ST']:\n",
    "        catchment_list_ST3.append(catchment_list[i])\n",
    "        \n",
    "catchment_list_ST = catchment_list_ST1, catchment_list_ST2, catchment_list_ST3\n",
    "\n",
    "for i in range(len(catchment_list)):\n",
    "    if df_output.loc[catchment_list[i],'SI'] < cut1_SI:\n",
    "        catchment_list_SI1.append(catchment_list[i])\n",
    "    elif cut1_SI <= df_output.loc[catchment_list[i],'SI'] < cut2_SI:\n",
    "        catchment_list_SI2.append(catchment_list[i])\n",
    "    elif cut2_SI <= df_output.loc[catchment_list[i],'SI']:\n",
    "        catchment_list_SI3.append(catchment_list[i])\n",
    "        \n",
    "catchment_list_SI = catchment_list_SI1, catchment_list_SI2, catchment_list_SI3\n",
    "\n",
    "for i in range(len(catchment_list)):\n",
    "    if df_output.loc[catchment_list[i],'is_dur'] < cut1_isdur:\n",
    "        catchment_list_isdur1.append(catchment_list[i])\n",
    "    elif cut1_isdur <= df_output.loc[catchment_list[i],'is_dur'] < cut2_isdur:\n",
    "        catchment_list_isdur2.append(catchment_list[i])\n",
    "    elif cut2_isdur <= df_output.loc[catchment_list[i],'is_dur']:\n",
    "        catchment_list_isdur3.append(catchment_list[i])\n",
    "        \n",
    "catchment_list_isdur = catchment_list_isdur1, catchment_list_isdur2, catchment_list_isdur3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7f97c-7ad7-45e5-9c88-09e2b9fede46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculate expected Sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdfb534-b90e-456d-ba5f-7d7dc12729af",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "catchment_list = catchment_list_GB\n",
    "\n",
    "for i in range(len(catchment_list)):  \n",
    "    # Import data and select right dates\n",
    "    data = pd.read_csv('1_Data/8344e4f3-d2ea-44f5-8afa-86d2987543a9/data/timeseries/CAMELS_GB_hydromet_timeseries_'+str(catchment_list[i])+str(\"_19701001-20150930.csv\"), delimiter=',', parse_dates=[0], skipinitialspace=True)\n",
    "    data.loc[:,'dt'] = pd.to_datetime(data['date'])\n",
    "    data.index = data['dt']\n",
    "    data = data[3379:-273]\n",
    "    \n",
    "    # Compute the Makkink potential evaporation\n",
    "    Eref = calc_Makkink_GB(data['temperature'],data['shortwave_rad'])\n",
    "    data['Ep_MAK'] = Eref\n",
    "        \n",
    "    # Compute mean values    \n",
    "    Ep = data['Ep_MAK'].mean()    \n",
    "    T = data['temperature'].mean()\n",
    "    P  = data['precipitation'].mean()\n",
    "    Q  = data['discharge_spec'].mean()\n",
    "        \n",
    "    # Compute actual evaporation and Evaporative Index and Aridity index\n",
    "    Ea = P - Q  \n",
    "    AI = Ep / P   \n",
    "    EI = Ea / P \n",
    "    \n",
    "    \n",
    "    # Seperate data into slices\n",
    "    data['year'] = pd.DatetimeIndex(data['date']).year\n",
    "    for j in range(len(yrsl)):\n",
    "        if j > 0:            \n",
    "            datanew = data.loc[(yrcut[j] <= data['year']) & (data['year'] < yrcut[j+1])]\n",
    "            c = colors[j]\n",
    "            yearslice = yrsl[j]\n",
    "\n",
    "            # Compute the Makkink potential evaporation\n",
    "            Ep = datanew['Ep_MAK'].mean()    \n",
    "            T = datanew['temperature'].mean()\n",
    "            P  = datanew['precipitation'].mean()\n",
    "\n",
    "            # Compute actual evaporation and Evaporative Index and Aridity index\n",
    "            AI = Ep / P   \n",
    "            EI = Ea / P \n",
    "\n",
    "            EI_exp = df_output.loc[catchment_list[i],[f'EI expected {yrsl[j]}']].item()\n",
    "\n",
    "            Ea_exp = EI_exp * P\n",
    "\n",
    "            # Calculate root zone storage deficits\n",
    "            RP    = 20 # Return-period of 20 years\n",
    "            P_ts  = datanew['precipitation']\n",
    "            EP_ts = datanew['Ep_MAK']\n",
    "\n",
    "            Et = np.zeros(len(P_ts))\n",
    "            SD = np.zeros(len(P_ts))\n",
    "\n",
    "            for z in range(len(P_ts)):\n",
    "                Et[z] = (EP_ts[z]/Ep) * Ea_exp\n",
    "                if z == 0:\n",
    "                    SD[z] = min(0, P_ts[z] - Et[z])\n",
    "                else:\n",
    "                    SD[z] = min(0, SD[z-1] + P_ts[z] - Et[z])\n",
    "            datanew.loc[:,'SD'] = SD\n",
    "\n",
    "\n",
    "            datanew['year'] = pd.DatetimeIndex(datanew['date']).year\n",
    "            df_out = pd.DataFrame(index = datanew.index)\n",
    "            df_out['hydroyear'] = datanew['year']\n",
    "            df_out['SD_sum'] = datanew['SD']\n",
    "            Sr = rootzone(df_out,RP)[0]\n",
    "\n",
    "            df_output.loc[catchment_list[i],[f'Sr expected {yrsl[j]}']] = Sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af594ba8-d402-40c4-a3c2-53181284872d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculate Sr change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e8f99-973f-4b25-a7d5-6945aa6f5231",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(catchment_list)):\n",
    "    for j in range(len(yrsl)):\n",
    "        if j > 0:\n",
    "            Sr = df_output.loc[catchment_list[i],[f'Sr actual {yrsl[j]}']].item()\n",
    "            Sr_exp = df_output.loc[catchment_list[i],[f'Sr expected {yrsl[j]}']].item()\n",
    "            Sr_dev = Sr - Sr_exp\n",
    "            Sr_dev_rel = Sr_dev / Sr\n",
    "            # Sr_dev_rel = \"{:.0%}\".format(Sr_dev_rel)\n",
    "            df_output.loc[[catchment_list[i]],[f'Sr deviation {yrsl[j]}']] = Sr_dev\n",
    "            df_output.loc[[catchment_list[i]],[f'Sr relative {yrsl[j]}']] = Sr_dev_rel\n",
    "            \n",
    "display(df_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363532a1-fd1d-48b2-916d-85e72f4b910d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76585523-0dd5-4b73-a2f5-d96e42a6451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv(f'C:/Users/Nienke Tempel/Documents/Thesis/6. Code/1_Budyko_combined/1_Input/{Input}/GB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1748ab0-8bfc-42df-b93a-5b49d249f73b",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Histogram EI deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a3994-869c-40d3-b567-1c5430d6a67e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Histogram EI deviations combined time periods (not overlapping) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0774456-21c2-4172-b9ac-fa10afb2b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Histogram EI deviations combined time periods (not overlapping) - ONE DECADE - cumulative\"\n",
    "\n",
    "import seaborn as sns\n",
    "                          \n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4.5)\n",
    "fig.set_figwidth(3.5)\n",
    "EI_dev_grouped = [\"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\"]\n",
    "                   \n",
    "    \n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    EI_dev_total = []        \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "            EI_dev_total.append(EI_dev)   \n",
    "                \n",
    "    EI_dev_grouped[j-1] = EI_dev_total\n",
    "    w[j-1] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev_grouped = EI_dev_grouped[0:3]\n",
    "w = w[0:3]\n",
    "labels = yrsl[1:4]\n",
    "c = colors[1:4]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev_grouped, bins=15, alpha = 0.75, color = c, label=labels, weights=w, orientation=\"horizontal\")\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "ax2 = plt.gca().twiny()\n",
    "\n",
    "for i in range(len(EI_dev_grouped)):\n",
    "    sns.histplot(data=EI_dev_grouped[i], element=\"step\", fill=False,\n",
    "    cumulative=True, stat=\"density\", common_norm=False, color=c[i], y = EI_dev_grouped[i], linewidth = 2, linestyle='solid')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "ax2.grid('false')\n",
    "ax2.set_xlabel('Cumulative')\n",
    "\n",
    "# print(EI_dev_grouped)\n",
    "ax2.grid(False)\n",
    "ax2.set_facecolor(\"None\")\n",
    "\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_timeslices1.png')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ffc0f-9b30-41d0-8d31-5b40ffb5ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Histogram EI deviations combined time periods (not overlapping) - PAST DECADE - cumulative\"\n",
    "\n",
    "import seaborn as sns\n",
    "                          \n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4.5)\n",
    "fig.set_figwidth(3.5)\n",
    "EI_dev_grouped = [\"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\"]\n",
    "                            \n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    EI_dev_total = []        \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation past decades {yrsl[j]}']].item()\n",
    "            EI_dev_total.append(EI_dev)   \n",
    "                \n",
    "    EI_dev_grouped[j-1] = EI_dev_total\n",
    "    w[j-1] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev_grouped = EI_dev_grouped[0:3]\n",
    "w = w[0:3]\n",
    "labels = yrsl[1:4]\n",
    "c = colors[1:4]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev_grouped, bins=15, alpha = 0.75, color = c, label=labels, weights=w, orientation=\"horizontal\")\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "ax2 = plt.gca().twiny()\n",
    "\n",
    "for i in range(len(EI_dev_grouped)):\n",
    "    sns.histplot(data=EI_dev_grouped[i], element=\"step\", fill=False,\n",
    "    cumulative=True, stat=\"density\", common_norm=False, color=c[i], y = EI_dev_grouped[i], linewidth = 2)\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "ax2.grid('false')\n",
    "ax2.set_xlabel('Cumulative')\n",
    "\n",
    "# print(EI_dev_grouped)\n",
    "ax2.grid(False)\n",
    "ax2.set_facecolor(\"None\")\n",
    "\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_timeslices1.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7d9c0-9178-44a3-bf12-05c451d8b095",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Histogram EI deviations grouped by aridity (not overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f1d0c-955b-4bff-bc6f-69cca7668266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Histogram EI deviations grouped by aridity (not overlapping)\"\n",
    "\n",
    "fig = plt.figure()\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "EI_dev_grouped = [\"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\"]\n",
    "labels = [f\"AI < 0.33\", f\"0.33 < AI < 0.66\", f\"0.66 < AI\"]\n",
    "                            \n",
    "                \n",
    "print(catchment_list_AI)\n",
    "for a in range(len(catchment_list_AI)):\n",
    "    catchment_list = catchment_list_AI[a]\n",
    "    EI_dev_total = []        \n",
    "    for j in range(len(yrsl)):  \n",
    "        if j > 0:\n",
    "            for i in range(len(catchment_list)):\n",
    "                EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "                EI_dev_total.append(EI_dev)                            \n",
    "                \n",
    "                EI_dev_grouped[a] = EI_dev_total\n",
    "                w[a] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "                \n",
    "# Label maken\n",
    "\n",
    "des = 'AI'                \n",
    "\n",
    "n1 = len(EI_dev_grouped[0]) \n",
    "n2 = len(EI_dev_grouped[1])\n",
    "n3 = len(EI_dev_grouped[2])\n",
    "\n",
    "print(n1, n2, n3)\n",
    "                \n",
    "labels = [f\"{des} < {cut1_AI} (n={n1})\", f\"{cut1_AI} < {des} < {cut2_AI} (n={n2})\", f\"{des} > {cut2_AI} (n={n3})\"]               \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev_grouped = EI_dev_grouped[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors2[0:3]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "# plt.hist(EI_dev_grouped, bins=15, alpha = 1, color = c, label=labels, weights=w, orientation=\"horizontal\")\n",
    "plt.hist(EI_dev_grouped, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation=\"horizontal\")\n",
    "\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_aridity_notoverlapping_v1.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b9509-ec99-4839-a86e-56255f62ce0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Histogram EI deviations grouped by seasonality index (not overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebddd01-af76-4e5c-8295-a196c8dc5f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"Histogram EI deviations grouped by index (not overlapping)\"\n",
    "\n",
    "# Hetzelfde bij elke\n",
    "\n",
    "fig = plt.figure()\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "\n",
    "EI_dev_grouped = [\"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\"]\n",
    "labels = [f\"SI < {cut1_SI}\",\n",
    "          f\"{cut1_SI} <= SI < {cut2_SI}\",\n",
    "          f\"{cut2_SI} <= SI\"]\n",
    "\n",
    "print(len(catchment_list_SI[0]))\n",
    "print(len(catchment_list_SI[1]))\n",
    "print(len(catchment_list_SI[2]))\n",
    "\n",
    "for a in range(len(catchment_list_SI)):\n",
    "    catchment_list = catchment_list_SI[a]\n",
    "    EI_dev_total = []        \n",
    "    for j in range(len(yrsl)):  \n",
    "        if j > 0:\n",
    "            for i in range(len(catchment_list)):\n",
    "                EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "                EI_dev_total.append(EI_dev)                            \n",
    "                \n",
    "                EI_dev_grouped[a] = EI_dev_total\n",
    "                w[a] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "# Label maken\n",
    "\n",
    "des = 'SI'                \n",
    "\n",
    "n1 = len(EI_dev_grouped[0]) \n",
    "n2 = len(EI_dev_grouped[1])\n",
    "n3 = len(EI_dev_grouped[2])\n",
    "\n",
    "print(n1, n2, n3)\n",
    "                \n",
    "labels = [f\"{des} < {cut1_SI} (n={n1})\", f\"{cut1_SI} < {des} < {cut2_SI} (n={n2})\", f\"{des} > {cut2_SI} (n={n3})\"]              \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev_grouped = EI_dev_grouped[0:2]\n",
    "w = w[0:2]\n",
    "labels = labels[0:2]\n",
    "c = colors2[0:2]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "# plt.hist(EI_dev_grouped, bins=15, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.hist(EI_dev_grouped, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_SI.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65040452-c4d6-4132-b4b9-bfd7c28b73a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Histogram EI deviations grouped by seasonality timing (not overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521b821-39b1-467b-bcba-68aa3f7d40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Histogram EI deviations grouped by ST (not overlapping)\"\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "EI_dev_grouped = [\"\", \"\", \"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\", \"\", \"\"]\n",
    "labels = [f\"ST < {cut1_ST}\",\n",
    "          f\"{cut1_ST} <= ST < {cut2_ST}\",\n",
    "          f\"{cut2_ST} <= ST\"]\n",
    "\n",
    "print(catchment_list_ST)\n",
    "\n",
    "print(len(catchment_list_ST[0]))\n",
    "print(len(catchment_list_ST[1]))\n",
    "print(len(catchment_list_ST[2]))\n",
    "\n",
    "\n",
    "                \n",
    "for a in range(len(catchment_list_ST)):\n",
    "    catchment_list = catchment_list_ST[a]\n",
    "    EI_dev_total = []        \n",
    "    for j in range(len(yrsl)):  \n",
    "        if j > 0:\n",
    "            for i in range(len(catchment_list)):\n",
    "                EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "                EI_dev_total.append(EI_dev)                            \n",
    "                \n",
    "                EI_dev_grouped[a] = EI_dev_total\n",
    "                w[a] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "# Label maken\n",
    "\n",
    "des = 'ST'                \n",
    "\n",
    "n1 = len(EI_dev_grouped[0]) \n",
    "n2 = len(EI_dev_grouped[1])\n",
    "n3 = len(EI_dev_grouped[2])\n",
    "\n",
    "print(n1, n2, n3)\n",
    "                \n",
    "labels = [f\"{des} < {cut1_ST} (n={n1})\", f\"{cut1_ST} < {des} < {cut2_ST} (n={n2})\", f\"{des} > {cut2_ST} (n={n3})\"]                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev_grouped = EI_dev_grouped[1:3]\n",
    "w = w[1:3]\n",
    "labels = labels[1:3]\n",
    "c = colors2[1:3]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "# plt.hist(EI_dev_grouped, bins=15, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.hist(EI_dev_grouped, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_ST_notoverlapping_v1.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06a745-5456-47e3-90e6-42c559d711c1",
   "metadata": {},
   "source": [
    "### Histogram EI deviations grouped by Interstorm duration (not overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f89e9a-61b0-4a21-8451-2e53051a0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Histogram EI deviations grouped by interstorm (not overlapping)\"\n",
    "\n",
    "# Hetzelfde bij elke\n",
    "\n",
    "fig = plt.figure()\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "EI_dev_grouped = [\"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\"]\n",
    "labels = [f\"Is_dur < {cut1_isdur}\",\n",
    "          f\"{cut1_isdur} <= Is_dur < {cut2_isdur}\",\n",
    "          f\"{cut2_isdur} <= Is_dur\"]\n",
    "\n",
    "print(catchment_list_isdur)\n",
    "\n",
    "\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "\n",
    "for a in range(len(catchment_list_isdur)):\n",
    "    catchment_list = catchment_list_isdur[a]\n",
    "    EI_dev_total = []        \n",
    "    for j in range(len(yrsl)):  \n",
    "        if j > 0:\n",
    "            for i in range(len(catchment_list)):\n",
    "                EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "                EI_dev_total.append(EI_dev)                            \n",
    "                \n",
    "                EI_dev_grouped[a] = EI_dev_total\n",
    "                w[a] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "# Label maken\n",
    "\n",
    "des = 'is_dur'                \n",
    "\n",
    "n1 = len(EI_dev_grouped[0]) \n",
    "n2 = len(EI_dev_grouped[1])\n",
    "n3 = len(EI_dev_grouped[2])\n",
    "\n",
    "print(n1, n2, n3)\n",
    "                \n",
    "labels = [f\"{des} < {cut1_isdur} (n={n1})\", f\"{cut1_isdur} < {des} < {cut2_isdur} (n={n2})\", f\"{des} > {cut2_isdur} (n={n3})\"]             \n",
    "                \n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev_grouped = EI_dev_grouped[0:2]\n",
    "w = w[0:2]\n",
    "labels = labels[0:2]\n",
    "c = colors2[0:2]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "# plt.hist(EI_dev_grouped, bins=15, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.hist(EI_dev_grouped, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_isdur_notoverlapping_v1.png')   \n",
    "\n",
    "print(len(catchment_list_isdur[0]))\n",
    "print(len(catchment_list_isdur[1]))\n",
    "print(len(catchment_list_isdur[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1f471-4b00-40e3-b79f-a4dc656f1e4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Histogram EI deviations grouped by Mean annual values (not overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755a0f4-464c-444e-8958-f3bea7412111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Histogram EI deviations grouped by P (not overlapping)\"\n",
    "\n",
    "# Hetzelfde bij elke\n",
    "\n",
    "fig = plt.figure()\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "EI_dev_grouped = [\"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\"]\n",
    "labels = [f\"P < {cut1_Pa}\",\n",
    "          f\"{cut1_Pa} <= P < {cut2_Pa}\",\n",
    "          f\"{cut2_Pa} <= P\"]\n",
    "\n",
    "print(catchment_list_Pa)\n",
    "for a in range(len(catchment_list_Pa)):\n",
    "    catchment_list = catchment_list_Pa[a]\n",
    "    EI_dev_total = []        \n",
    "    for j in range(len(yrsl)):  \n",
    "        if j > 0:\n",
    "            for i in range(len(catchment_list)):\n",
    "                EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "                EI_dev_total.append(EI_dev)                            \n",
    "                \n",
    "                EI_dev_grouped[a] = EI_dev_total\n",
    "                w[a] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "# Label maken\n",
    "\n",
    "des = 'P'                \n",
    "\n",
    "n1 = len(EI_dev_grouped[0]) \n",
    "n2 = len(EI_dev_grouped[1])\n",
    "n3 = len(EI_dev_grouped[2])\n",
    "\n",
    "print(n1, n2, n3)\n",
    "                \n",
    "labels = [f\"{des} < {cut1_Pa} (n={n1})\", f\"{cut1_Pa} < {des} < {cut2_Pa} (n={n2})\", f\"{des} > {cut2_Pa} (n={n3})\"]                            \n",
    "                \n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev_grouped = EI_dev_grouped[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors2[0:3]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "# plt.hist(EI_dev_grouped, bins=15, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.hist(EI_dev_grouped, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_Pa_notoverlapping_v1.png')   \n",
    "\n",
    "print(len(catchment_list_Pa[0]))\n",
    "print(len(catchment_list_Pa[1]))\n",
    "print(len(catchment_list_Pa[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda781a-673a-42ef-a784-e15ad893e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Histogram EI deviations grouped by Ep (not overlapping)\"\n",
    "\n",
    "# Hetzelfde bij elke\n",
    "\n",
    "fig = plt.figure()\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "EI_dev_grouped = [\"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\"]\n",
    "labels = [f\"Ep < {cut1_Epa}\",\n",
    "          f\"{cut1_Epa} <= Ep < {cut2_Epa}\",\n",
    "          f\"{cut2_Epa} <= Ep\"]\n",
    "\n",
    "for a in range(len(catchment_list_Epa)):\n",
    "    catchment_list = catchment_list_Epa[a]\n",
    "    EI_dev_total = []        \n",
    "    for j in range(len(yrsl)):  \n",
    "        if j > 0:\n",
    "            for i in range(len(catchment_list)):\n",
    "                EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "                EI_dev_total.append(EI_dev)                            \n",
    "                \n",
    "                EI_dev_grouped[a] = EI_dev_total\n",
    "                w[a] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "# Label maken\n",
    "\n",
    "des = 'Ep'                \n",
    "\n",
    "n1 = len(EI_dev_grouped[0]) \n",
    "n2 = len(EI_dev_grouped[1])\n",
    "n3 = len(EI_dev_grouped[2])\n",
    "\n",
    "print(n1, n2, n3)\n",
    "                \n",
    "labels = [f\"{des} < {cut1_Epa} (n={n1})\", f\"{cut1_Epa} < {des} < {cut2_Epa} (n={n2})\", f\"{des} > {cut2_Epa} (n={n3})\"]                    \n",
    "                \n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "print(catchment_list_Epa)\n",
    "EI_dev_grouped = EI_dev_grouped[0:2]\n",
    "w = w[0:2]\n",
    "labels = labels[0:2]\n",
    "c = colors2[0:2]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "# plt.hist(EI_dev_grouped, bins=15, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.hist(EI_dev_grouped, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_Ep_notoverlapping_v1.png')   \n",
    "\n",
    "print(len(catchment_list_Epa[0]))\n",
    "print(len(catchment_list_Epa[1]))\n",
    "print(len(catchment_list_Epa[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42943cfe-91c8-4ec3-a171-40269214dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Histogram EI deviations grouped by T (not overlapping)\"\n",
    "\n",
    "# Hetzelfde bij elke\n",
    "\n",
    "fig = plt.figure()\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "EI_dev_grouped = [\"\", \"\", \"\"]\n",
    "w = [\"\", \"\", \"\"]\n",
    "labels = [f\"T < {cut1_T}\",\n",
    "          f\"{cut1_T} <= T < {cut2_T}\",\n",
    "          f\"{cut2_T} <= T\"]\n",
    "\n",
    "for a in range(len(catchment_list_T)):\n",
    "    catchment_list = catchment_list_T[a]\n",
    "    EI_dev_total = []        \n",
    "    for j in range(len(yrsl)):  \n",
    "        if j > 0:\n",
    "            for i in range(len(catchment_list)):\n",
    "                EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "                EI_dev_total.append(EI_dev)                            \n",
    "                \n",
    "            EI_dev_grouped[a] = EI_dev_total\n",
    "            w[a] = np.ones_like(EI_dev_total)/(len(EI_dev_total))\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "# Label maken\n",
    "\n",
    "des = 'T'                \n",
    "\n",
    "n1 = len(EI_dev_grouped[0]) \n",
    "n2 = len(EI_dev_grouped[1])\n",
    "n3 = len(EI_dev_grouped[2])\n",
    "\n",
    "print(n1, n2, n3)\n",
    "                \n",
    "labels = [f\"{des} < {cut1_T} (n={n1})\", f\"{cut1_T} < {des} < {cut2_T} (n={n2})\", f\"{des} > {cut2_T} (n={n3})\"]                        \n",
    "                \n",
    "                \n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "print(catchment_list_T)\n",
    "EI_dev_grouped = EI_dev_grouped[0:2]\n",
    "w = w[0:2]\n",
    "labels = labels[0:2]\n",
    "c = colors2[0:2]\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "# plt.hist(EI_dev_grouped, bins=15, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.hist(EI_dev_grouped, bins=15, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "plt.savefig(f'2_Output/{output}/Histograms/Histogram_T_notoverlapping_v1.png')   \n",
    "\n",
    "print(len(catchment_list_T[0]))\n",
    "print(len(catchment_list_T[1]))\n",
    "print(len(catchment_list_T[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db226185-c67b-4efc-89e0-8e6626d8faa5",
   "metadata": {},
   "source": [
    "## Change vs change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b65c61-a1cf-421d-a83d-9be4b31d8245",
   "metadata": {},
   "source": [
    "### Aridity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83775e7b-ab43-4df2-a495-0bb2a3d69bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Change vs change: aridity\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "\n",
    "catchment_list = catchment_list_GB\n",
    "    \n",
    "\n",
    "change1 = -0.05\n",
    "change2 = 0.05    \n",
    "    \n",
    "    \n",
    "des_change1 = []\n",
    "des_change2 = []\n",
    "des_change3 = []\n",
    "\n",
    "des_change_total = []\n",
    "\n",
    "EI_dev1 = []\n",
    "EI_dev2 = []\n",
    "EI_dev3 = []\n",
    "\n",
    "des = 'AI'\n",
    "\n",
    "\n",
    "w = [\"\", \"\", \"\"]\n",
    "\n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            des_change = df_output.loc[catchment_list[i],[f'{des}_change {yrsl[j]}']].item()\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "            des_change_total.append(des_change)\n",
    "            if des_change < change1:\n",
    "                des_change1.append(des_change)\n",
    "                EI_dev1.append(EI_dev)    \n",
    "            elif change1 <= des_change and des_change < change2:\n",
    "                des_change2.append(des_change)\n",
    "                EI_dev2.append(EI_dev)\n",
    "            elif change2 <= des_change:\n",
    "                des_change3.append(des_change)\n",
    "                EI_dev3.append(EI_dev)\n",
    "                \n",
    "                \n",
    "EI_dev = EI_dev1, EI_dev2, EI_dev3\n",
    "\n",
    "n1 = len(EI_dev1) \n",
    "n2 = len(EI_dev2)\n",
    "n3 = len(EI_dev3)\n",
    "\n",
    "print(n1, n2, n3)\n",
    "\n",
    "print(min(des_change_total))\n",
    "print(max(des_change_total))\n",
    "for a in range(3):\n",
    "    if EI_dev[a] != 0:\n",
    "        w[a] = np.ones_like(EI_dev[a])/(len(EI_dev[a]))\n",
    "    else:\n",
    "        w[a] = np.array(0)\n",
    "        \n",
    "        \n",
    "labels = [f\"{des} < {change1} (n={n1})\", f\"{change1} < {des} < {change2} (n={n2})\", f\"{des} > {change2} (n={n3})\"]\n",
    "\n",
    "\n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev = EI_dev[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors4[0:3]  \n",
    "\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "            \n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "                \n",
    "plt.savefig(f'2_Output/{output}/Results/AI_change.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798424a-605a-41e1-ba2b-07758a6ec82b",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e27822-d8fb-430f-b6ca-70845a5f647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Change vs change: precipitation\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "\n",
    "catchment_list = catchment_list_GB\n",
    "    \n",
    "\n",
    "change1 = -20\n",
    "change2 = 20\n",
    "    \n",
    "    \n",
    "des_change1 = []\n",
    "des_change2 = []\n",
    "des_change3 = []\n",
    "\n",
    "des_change_total = []\n",
    "\n",
    "EI_dev1 = []\n",
    "EI_dev2 = []\n",
    "EI_dev3 = []\n",
    "\n",
    "des = 'Pa'\n",
    "\n",
    "\n",
    "w = [\"\", \"\", \"\"]\n",
    "\n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            des_change = df_output.loc[catchment_list[i],[f'{des}_change {yrsl[j]}']].item()\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "            des_change_total.append(des_change)\n",
    "            if des_change < change1:\n",
    "                des_change1.append(des_change)\n",
    "                EI_dev1.append(EI_dev)    \n",
    "            elif change1 <= des_change and des_change < change2:\n",
    "                des_change2.append(des_change)\n",
    "                EI_dev2.append(EI_dev)\n",
    "            elif change2 <= des_change:\n",
    "                des_change3.append(des_change)\n",
    "                EI_dev3.append(EI_dev)\n",
    "                \n",
    "                \n",
    "EI_dev = EI_dev1, EI_dev2, EI_dev3\n",
    "\n",
    "n1 = len(EI_dev1) \n",
    "n2 = len(EI_dev2)\n",
    "n3 = len(EI_dev3)\n",
    "\n",
    "print(n1, n2, n3)\n",
    "\n",
    "print(min(des_change_total))\n",
    "print(max(des_change_total))\n",
    "for a in range(3):\n",
    "    if EI_dev[a] != 0:\n",
    "        w[a] = np.ones_like(EI_dev[a])/(len(EI_dev[a]))\n",
    "    else:\n",
    "        w[a] = np.array(0)\n",
    "        \n",
    "        \n",
    "labels = [f\"{des} < {change1} (n={n1})\", f\"{change1} < {des} < {change2} (n={n2})\", f\"{des} > {change2} (n={n3})\"]\n",
    "\n",
    "\n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev = EI_dev[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors4[0:3]  \n",
    "\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "            \n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "                \n",
    "plt.savefig(f'2_Output/{output}/Results/AI_change.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94431410-1e54-4851-9336-b0816dc78982",
   "metadata": {},
   "source": [
    "## Evaporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f7461f-79b5-444e-a602-5a7eb07f9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Change vs change: evaporation\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "\n",
    "catchment_list = catchment_list_GB\n",
    "    \n",
    "\n",
    "change1 = -10\n",
    "change2 = 10\n",
    "    \n",
    "    \n",
    "des_change1 = []\n",
    "des_change2 = []\n",
    "des_change3 = []\n",
    "\n",
    "des_change_total = []\n",
    "\n",
    "EI_dev1 = []\n",
    "EI_dev2 = []\n",
    "EI_dev3 = []\n",
    "\n",
    "des = 'Epa'\n",
    "\n",
    "\n",
    "w = [\"\", \"\", \"\"]\n",
    "\n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            des_change = df_output.loc[catchment_list[i],[f'{des}_change {yrsl[j]}']].item()\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "            des_change_total.append(des_change)\n",
    "            if des_change < change1:\n",
    "                des_change1.append(des_change)\n",
    "                EI_dev1.append(EI_dev)    \n",
    "            elif change1 <= des_change and des_change < change2:\n",
    "                des_change2.append(des_change)\n",
    "                EI_dev2.append(EI_dev)\n",
    "            elif change2 <= des_change:\n",
    "                des_change3.append(des_change)\n",
    "                EI_dev3.append(EI_dev)\n",
    "\n",
    "EI_dev1 = ''                \n",
    "                \n",
    "EI_dev = EI_dev1, EI_dev2, EI_dev3\n",
    "\n",
    "n1 = len(EI_dev1) \n",
    "n2 = len(EI_dev2)\n",
    "n3 = len(EI_dev3)\n",
    "\n",
    "print(n1, n2, n3)\n",
    "\n",
    "print(min(des_change_total))\n",
    "print(max(des_change_total))\n",
    "for a in range(3):\n",
    "    if EI_dev[a] != 0 and EI_dev[a] != '':\n",
    "        w[a] = np.ones_like(EI_dev[a])/(len(EI_dev[a]))\n",
    "    else:\n",
    "        w[a] = np.array(0)\n",
    "        \n",
    "        \n",
    "labels = [f\"{des} < {change1} (n={n1})\", f\"{change1} < {des} < {change2} (n={n2})\", f\"{des} > {change2} (n={n3})\"]\n",
    "\n",
    "\n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev = EI_dev[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors4[0:3]  \n",
    "\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "            \n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "                \n",
    "plt.savefig(f'2_Output/{output}/Results/AI_change.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa61a3c-f5a7-4f26-9419-cab74e4b9f68",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e8270-d840-4763-93bf-55ffda7be29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Change vs change: temperature\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "\n",
    "catchment_list = catchment_list_GB\n",
    "    \n",
    "\n",
    "change1 = -0.2\n",
    "change2 = 0.2\n",
    "    \n",
    "    \n",
    "des_change1 = []\n",
    "des_change2 = []\n",
    "des_change3 = []\n",
    "\n",
    "des_change_total = []\n",
    "\n",
    "EI_dev1 = []\n",
    "EI_dev2 = []\n",
    "EI_dev3 = []\n",
    "\n",
    "des = 'T'\n",
    "\n",
    "\n",
    "w = [\"\", \"\", \"\"]\n",
    "\n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            des_change = df_output.loc[catchment_list[i],[f'{des}_change {yrsl[j]}']].item()\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "            des_change_total.append(des_change)\n",
    "            if des_change < change1:\n",
    "                des_change1.append(des_change)\n",
    "                EI_dev1.append(EI_dev)    \n",
    "            elif change1 <= des_change and des_change < change2:\n",
    "                des_change2.append(des_change)\n",
    "                EI_dev2.append(EI_dev)\n",
    "            elif change2 <= des_change:\n",
    "                des_change3.append(des_change)\n",
    "                EI_dev3.append(EI_dev)\n",
    "                \n",
    "                \n",
    "EI_dev = EI_dev1, EI_dev2, EI_dev3\n",
    "\n",
    "n1 = len(EI_dev1) \n",
    "n2 = len(EI_dev2)\n",
    "n3 = len(EI_dev3)\n",
    "\n",
    "print(n1, n2, n3)\n",
    "\n",
    "print(min(des_change_total))\n",
    "print(max(des_change_total))\n",
    "for a in range(3):\n",
    "    if EI_dev[a] != 0:\n",
    "        w[a] = np.ones_like(EI_dev[a])/(len(EI_dev[a]))\n",
    "    else:\n",
    "        w[a] = np.array(0)\n",
    "        \n",
    "        \n",
    "labels = [f\"{des} < {change1} (n={n1})\", f\"{change1} < {des} < {change2} (n={n2})\", f\"{des} > {change2} (n={n3})\"]\n",
    "\n",
    "\n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev = EI_dev[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors4[0:3]  \n",
    "\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "            \n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "                \n",
    "plt.savefig(f'2_Output/{output}/Results/AI_change.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483d769-cbc8-46c2-9382-97e136b17c27",
   "metadata": {},
   "source": [
    "## Interstorm duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655dd93f-6515-4bd5-baeb-9fba9eaceefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Change vs change: interstorm duration\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "\n",
    "catchment_list = catchment_list_GB\n",
    "    \n",
    "\n",
    "change1 = -0.1\n",
    "change2 = 0.1\n",
    "    \n",
    "    \n",
    "des_change1 = []\n",
    "des_change2 = []\n",
    "des_change3 = []\n",
    "\n",
    "des_change_total = []\n",
    "\n",
    "EI_dev1 = []\n",
    "EI_dev2 = []\n",
    "EI_dev3 = []\n",
    "\n",
    "des = 'is_dur'\n",
    "\n",
    "\n",
    "w = [\"\", \"\", \"\"]\n",
    "\n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            des_change = df_output.loc[catchment_list[i],[f'{des}_change {yrsl[j]}']].item()\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "            des_change_total.append(des_change)\n",
    "            if des_change < change1:\n",
    "                des_change1.append(des_change)\n",
    "                EI_dev1.append(EI_dev)    \n",
    "            elif change1 <= des_change and des_change < change2:\n",
    "                des_change2.append(des_change)\n",
    "                EI_dev2.append(EI_dev)\n",
    "            elif change2 <= des_change:\n",
    "                des_change3.append(des_change)\n",
    "                EI_dev3.append(EI_dev)\n",
    "                \n",
    "                \n",
    "EI_dev = EI_dev1, EI_dev2, EI_dev3\n",
    "\n",
    "n1 = len(EI_dev1) \n",
    "n2 = len(EI_dev2)\n",
    "n3 = len(EI_dev3)\n",
    "\n",
    "print(n1, n2, n3)\n",
    "\n",
    "print(min(des_change_total))\n",
    "print(max(des_change_total))\n",
    "for a in range(3):\n",
    "    if EI_dev[a] != 0:\n",
    "        w[a] = np.ones_like(EI_dev[a])/(len(EI_dev[a]))\n",
    "    else:\n",
    "        w[a] = np.array(0)\n",
    "        \n",
    "        \n",
    "labels = [f\"{des} < {change1} (n={n1})\", f\"{change1} < {des} < {change2} (n={n2})\", f\"{des} > {change2} (n={n3})\"]\n",
    "\n",
    "\n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev = EI_dev[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors4[0:3]  \n",
    "\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "            \n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "                \n",
    "plt.savefig(f'2_Output/{output}/Results/ISdur_change.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e668bb-9fbd-492a-ae96-3893b4857803",
   "metadata": {},
   "source": [
    "## Seasonality index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b78800-d01f-4af4-ae32-f9c2ae3ac2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Change vs change: Seasonality index\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "\n",
    "catchment_list = catchment_list_GB\n",
    "    \n",
    "\n",
    "change1 = -0.02\n",
    "change2 = 0.02\n",
    "    \n",
    "    \n",
    "des_change1 = []\n",
    "des_change2 = []\n",
    "des_change3 = []\n",
    "\n",
    "des_change_total = []\n",
    "\n",
    "EI_dev1 = []\n",
    "EI_dev2 = []\n",
    "EI_dev3 = []\n",
    "\n",
    "des = 'SI'\n",
    "\n",
    "\n",
    "w = [\"\", \"\", \"\"]\n",
    "\n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            des_change = df_output.loc[catchment_list[i],[f'{des}_change {yrsl[j]}']].item()\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "            des_change_total.append(des_change)\n",
    "            if des_change < change1:\n",
    "                des_change1.append(des_change)\n",
    "                EI_dev1.append(EI_dev)    \n",
    "            elif change1 <= des_change and des_change < change2:\n",
    "                des_change2.append(des_change)\n",
    "                EI_dev2.append(EI_dev)\n",
    "            elif change2 <= des_change:\n",
    "                des_change3.append(des_change)\n",
    "                EI_dev3.append(EI_dev)\n",
    "                \n",
    "                \n",
    "EI_dev = EI_dev1, EI_dev2, EI_dev3\n",
    "\n",
    "n1 = len(EI_dev1) \n",
    "n2 = len(EI_dev2)\n",
    "n3 = len(EI_dev3)\n",
    "\n",
    "print(n1, n2, n3)\n",
    "\n",
    "print(min(des_change_total))\n",
    "print(max(des_change_total))\n",
    "for a in range(3):\n",
    "    if EI_dev[a] != 0:\n",
    "        w[a] = np.ones_like(EI_dev[a])/(len(EI_dev[a]))\n",
    "    else:\n",
    "        w[a] = np.array(0)\n",
    "        \n",
    "        \n",
    "labels = [f\"{des} < {change1} (n={n1})\", f\"{change1} < {des} < {change2} (n={n2})\", f\"{des} > {change2} (n={n3})\"]\n",
    "\n",
    "\n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev = EI_dev[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors4[0:3]  \n",
    "\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "            \n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "                \n",
    "plt.savefig(f'2_Output/{output}/Results/AI_change.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e66f25-a66f-4994-a94c-c0f8208f6359",
   "metadata": {},
   "source": [
    "## Seasonality Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f871d-08c4-4ac8-b251-881de930fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Change vs change: Seasonality index\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "# fig.set_figheight(9)\n",
    "# fig.set_figwidth(3.5)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(1)\n",
    "\n",
    "catchment_list = catchment_list_GB\n",
    "    \n",
    "\n",
    "change1 = -0.02\n",
    "change2 = 0.02\n",
    "    \n",
    "    \n",
    "des_change1 = []\n",
    "des_change2 = []\n",
    "des_change3 = []\n",
    "\n",
    "des_change_total = []\n",
    "\n",
    "EI_dev1 = []\n",
    "EI_dev2 = []\n",
    "EI_dev3 = []\n",
    "\n",
    "des = 'ST'\n",
    "\n",
    "\n",
    "w = [\"\", \"\", \"\"]\n",
    "\n",
    "\n",
    "for j in range(len(yrsl)):  \n",
    "    if j > 0:\n",
    "        for i in range(len(catchment_list)):\n",
    "            des_change = df_output.loc[catchment_list[i],[f'{des}_change {yrsl[j]}']].item()\n",
    "            EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "            des_change_total.append(des_change)\n",
    "            if des_change < change1:\n",
    "                des_change1.append(des_change)\n",
    "                EI_dev1.append(EI_dev)    \n",
    "            elif change1 <= des_change and des_change < change2:\n",
    "                des_change2.append(des_change)\n",
    "                EI_dev2.append(EI_dev)\n",
    "            elif change2 <= des_change:\n",
    "                des_change3.append(des_change)\n",
    "                EI_dev3.append(EI_dev)\n",
    "                \n",
    "                \n",
    "EI_dev = EI_dev1, EI_dev2, EI_dev3\n",
    "\n",
    "n1 = len(EI_dev1) \n",
    "n2 = len(EI_dev2)\n",
    "n3 = len(EI_dev3)\n",
    "\n",
    "print(n1, n2, n3)\n",
    "\n",
    "print(min(des_change_total))\n",
    "print(max(des_change_total))\n",
    "for a in range(3):\n",
    "    if EI_dev[a] != 0:\n",
    "        w[a] = np.ones_like(EI_dev[a])/(len(EI_dev[a]))\n",
    "    else:\n",
    "        w[a] = np.array(0)\n",
    "        \n",
    "        \n",
    "labels = [f\"{des} < {change1} (n={n1})\", f\"{change1} < {des} < {change2} (n={n2})\", f\"{des} > {change2} (n={n3})\"]\n",
    "\n",
    "\n",
    "# Hier invullen welke niet arrays niet leeg zijn\n",
    "EI_dev = EI_dev[0:3]\n",
    "w = w[0:3]\n",
    "labels = labels[0:3]\n",
    "c = colors4[0:3]  \n",
    "\n",
    "\n",
    "# Dit kan je weer hetzelfde laten (alleen bins aanpassen)\n",
    "plt.hist(EI_dev, bins=10, alpha = 1, color = c, label=labels, weights=w, orientation='horizontal')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.ylabel('Error in prediction EI')\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=0))\n",
    "plt.axhspan(-0.2, -0.0, facecolor='black', alpha=0.3)\n",
    "            \n",
    "\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "                \n",
    "plt.savefig(f'2_Output/{output}/Results/AI_change.png')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1c5ff-fcd6-42c8-8365-6d2f613ae889",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031cae09-ac98-4a85-858f-2ddcc3a779eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(descriptors)):\n",
    "    plt.suptitle('CAMELS GB')\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(7)\n",
    "    \n",
    "    EI_dev_total = []\n",
    "    des_change_total = []\n",
    "    for j in range(len(yrsl)):  \n",
    "        if j > 0:\n",
    "            for i in range(len(catchment_list)):\n",
    "                des_change = df_output.loc[catchment_list[i],[f'{descriptors[k]}_change {yrsl[j]}']].item()\n",
    "                des_change_total.append(des_change)\n",
    "                EI_dev = df_output.loc[catchment_list[i],[f'EI deviation {yrsl[j]}']].item()\n",
    "                EI_dev_total.append(EI_dev)                            \n",
    "                            \n",
    "                plt.plot(df_output[f'{descriptors[k]}_change {yr}'], df_output[f'EI deviation {yrsl[j]}'], '.', c=colors[j])      \n",
    "\n",
    "    x = des_change_total\n",
    "    y = EI_dev_total\n",
    "    \n",
    "    pearson = pearsonr(x, y)\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    pearsony = np.zeros(len(x))\n",
    "    \n",
    "    for q in range(len(EI_dev_total)):\n",
    "        pearsony[q] = m * x[q] + b\n",
    "    axs.plot(x, pearsony, 'k')\n",
    "                \n",
    "        \n",
    "    axs.set_xlabel(f\"Change in {descriptors_names[k]}\")\n",
    "    axs.set_ylabel(f\"Devation Evaporative Index\")\n",
    "    axs.set_title(f\"CAMELS GB {descriptors_names[k]}\")\n",
    "    \n",
    "    \n",
    "    legend = [Line2D([0], [0], marker='.', color='gainsboro', label=f'{yrsl[1]}',\n",
    "                       markerfacecolor=f'{colors[1]}', markersize=15),\n",
    "              Line2D([0], [0], marker='.', color='gainsboro', label=f'{yrsl[2]}',\n",
    "                       markerfacecolor=f'{colors[2]}', markersize=15),\n",
    "             Line2D([0], [0], color='k', label=f\"Correlation of {pearson[0]:.2} with p-value of {pearson[1]:.4}\" ,\n",
    "                       markerfacecolor='k', markersize=10)]                    \n",
    "\n",
    "    axs.legend(handles=legend,loc='lower right')\n",
    "                \n",
    "    plt.savefig(f'2_Output/{output}/Results/Correlations_total{descriptors_names[k]}.png')   \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79695660-3c50-465f-992f-7a39d25cf387",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot correlations for seperate time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc964df-7c57-46a3-8e14-413f21b5bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(descriptors)):\n",
    "    n_tot = len(yrsl) - 1 \n",
    "    fig, axs = plt.subplots(1, n_tot)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(20)\n",
    "    plt.suptitle('CAMELS GB')\n",
    "    for j in range(len(yrsl)):\n",
    "        if j > 0:\n",
    "            yr = yrsl[j]\n",
    "            c = colors[j]\n",
    "            n = j - 1\n",
    "            \n",
    "            for c in range(len(df_output)):\n",
    "                axs[n].plot(df_output[f'{descriptors[k]}_change {yr}'], df_output[f'EI deviation {yr}'], '.')      \n",
    "\n",
    "            x = df_output[f'{descriptors[k]}_change {yr}']\n",
    "            y = df_output[f'EI deviation {yr}']\n",
    "\n",
    "                \n",
    "            pearson = pearsonr(x, y)\n",
    "\n",
    "            m, b = np.polyfit(x, y, 1)\n",
    "            axs[n].plot(x, m*x + b, 'k', label=f\"Correlation of {pearson[0]:.2} with p-value of {pearson[1]:.4}\" )\n",
    "            axs[n].legend(loc='lower right')\n",
    "                \n",
    "                \n",
    "            axs[n].set_xlabel(f\"Change in {descriptors_names[k]}\")\n",
    "            axs[n].set_ylabel(f\"Devation Evaporation Index\")\n",
    "            axs[n].set_title(f\"Change in {descriptors_names[k]} period of {yr}\")\n",
    "    plt.savefig(f'2_Output/{output}/Results/Correlations_per_slice{descriptors_names[k]}.png')   \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc06fe1-0143-4357-b7b2-a72ec3f06a71",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot EI expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ffe575-d948-459f-8b5d-03936e889036",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_list = catchment_list_GB\n",
    "\n",
    "for i in range(len(catchment_list)):\n",
    "    # Import data and select right dates\n",
    "    data = pd.read_csv('1_Data/8344e4f3-d2ea-44f5-8afa-86d2987543a9/data/timeseries/CAMELS_GB_hydromet_timeseries_'+str(catchment_list[i])+str(\"_19701001-20150930.csv\"), delimiter=',', parse_dates=[0], skipinitialspace=True)\n",
    "    data.loc[:,'dt'] = pd.to_datetime(data['date'])\n",
    "    data.index = data['dt']\n",
    "    data = data[3379:-273]\n",
    "    \n",
    "    # Compute the Makkink potential evaporation\n",
    "    Eref = calc_Makkink_GB(data['temperature'],data['shortwave_rad'])\n",
    "    data['Ep_MAK'] = Eref\n",
    "            \n",
    "    # Compute mean values    \n",
    "    Ep = data['Ep_MAK'].mean()    \n",
    "    T = data['temperature'].mean()\n",
    "    P  = data['precipitation'].mean()\n",
    "    Q  = data['discharge_spec'].mean()\n",
    "        \n",
    "    # Compute actual evaporation and Evaporative Index and Aridity index\n",
    "    Ea = P - Q  \n",
    "    AI = Ep / P   \n",
    "    EI = Ea / P    \n",
    "        \n",
    "    # budyko plot\n",
    "    budyko_curve_x = np.arange(1, 3, 0.05)\n",
    "    energy_limit_x = np.arange(0, 1.0001, 0.05)\n",
    "    x = np.arange(0, 1.0001, 0.05)\n",
    "    water_limit_y = 1 + budyko_curve_x*0\n",
    "    energy_limit_y = energy_limit_x\n",
    "    y = 1 + x*0\n",
    "    plt.minorticks_on()\n",
    "        \n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(10)\n",
    "    plt.suptitle(f'catchment_with_ID{catchment_list[i]}')\n",
    "        \n",
    "    axs[0].plot(energy_limit_x, energy_limit_y, c='k')\n",
    "    axs[0].plot(budyko_curve_x, water_limit_y,c='k')\n",
    "    axs[0].set_ylabel(\"Actual ET/P\")\n",
    "    axs[0].set_xlabel(\"Potential ET/P\")\n",
    "    axs[0].minorticks_on()\n",
    "        \n",
    "    # plot annual deficits\n",
    "    axs[1].set_ylabel(f'Root zone storage deficit [mm]')\n",
    "    data['year'] = pd.DatetimeIndex(data['date']).year  \n",
    "    \n",
    "    for j in range(len(yrsl)):\n",
    "        datanew = data.loc[(yrcut[j] <= data['year']) & (data['year'] < yrcut[j+1])]\n",
    "        AI = df_output.loc[catchment_list[i],[f'AI {yrsl[j]}']].item()\n",
    "        EI = df_output.loc[catchment_list[i],[f'EI {yrsl[j]}']].item()\n",
    "        w = df_output.loc[catchment_list[i],[f'omega {yrsl[j]}']].item()\n",
    "        c = colors[j]\n",
    "        yearslice = yrsl[j]\n",
    "        \n",
    "        # Compute the Makkink potential evaporation\n",
    "        Ep = datanew['Ep_MAK'].mean()    \n",
    "        T = datanew['temperature'].mean()\n",
    "        P  = datanew['precipitation'].mean()\n",
    "        Q  = datanew['discharge_spec'].mean()\n",
    "\n",
    "        # Compute actual evaporation and Evaporative Index and Aridity index\n",
    "        Ea = P - Q  \n",
    "        AI = Ep / P   \n",
    "        EI = Ea / P \n",
    "                            \n",
    "        # plot w function\n",
    "        AI_array = np.arange(0, 3, 0.05)\n",
    "        EI_out = w_function(AI_array, w)\n",
    "        axs[0].plot(AI_array, EI_out, color=c, linewidth = 0.5)\n",
    "        axs[0].plot(AI, EI, marker='.', color=c, markersize=10)\n",
    "        \n",
    "        if j > 0:\n",
    "            c_exp = colors[j-1]\n",
    "            EI_exp = df_output.loc[catchment_list[i],[f'EI expected {yrsl[j]}']].item()\n",
    "            axs[0].plot(AI, EI_exp, marker='d', color=c, markersize=5)\n",
    "            \n",
    "        # Calculate root zone storage deficits\n",
    "        RP    = 20 # Return-period of 20 years\n",
    "        P_ts  = datanew['precipitation']\n",
    "        EP_ts = datanew['Ep_MAK']\n",
    "\n",
    "        Et = np.zeros(len(P_ts))\n",
    "        SD = np.zeros(len(P_ts))\n",
    "\n",
    "        for z in range(len(P_ts)):\n",
    "            Et[z] = (EP_ts[z]/Ep) * Ea\n",
    "            if z == 0:\n",
    "                SD[z] = min(0, P_ts[z] - Et[z])\n",
    "            else:\n",
    "                SD[z] = min(0, SD[z-1] + P_ts[z] - Et[z])\n",
    "        datanew.loc[:,'SD'] = SD\n",
    "\n",
    "        axs[1].plot(datanew['SD'], linewidth = 0.5, c=c)\n",
    "        \n",
    "    legend_0 = [Line2D([0], [0], marker='d', color='lightgrey', label='Expected value EI',\n",
    "                       markerfacecolor='k', markersize=10),\n",
    "                Line2D([0], [0], marker='.', color='lightgrey', label='Actual value EI',\n",
    "                       markerfacecolor='k', markersize=15)]\n",
    "    \n",
    "    legend_1 = [Line2D([0], [0], color=colors[0], lw=1, label=f'{yrsl[0]}'),\n",
    "                Line2D([0], [0], color=colors[1], lw=1, label=f'{yrsl[1]}'),\n",
    "                Line2D([0], [0], color=colors[2], lw=1, label=f'{yrsl[2]}')]\n",
    "                       \n",
    "\n",
    "    axs[0].legend(handles=legend_0,loc='lower right')\n",
    "    axs[1].legend(handles=legend_1,loc='lower right')\n",
    "    plt.savefig(f'2_Output/{output}/Catchments2/Expected_Budyko_and_deficits_nr_of_catchment_with_ID{catchment_list[i]}.png')   \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c883d2d-9646-42a0-acbd-28d0127bd44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da590bb-b5b9-4cc2-81c3-79f1ce375e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59117b25-b38b-4942-b680-bbc93b02b273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
